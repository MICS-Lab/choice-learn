{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to choice-learn's data management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## ChoiceDataset - Getting Started !\n",
    "\n",
    "In order to estimate a model using the choice-learn API, you will first need to wrap your dataset within a ChoiceDataset.\n",
    "\n",
    "choice-learn ChoiceDataset aims at being able to handle large datasets, typically by limiting the usage of memory to store several times the same feature.\n",
    "We define two sources of features, the items and the contexts.\n",
    "\n",
    "<ins>**Items**</ins> represent a product, an alternative that can be chosen by the customer at some point.\n",
    "\n",
    "<ins>**Contexts**</ins> represent the contexts surrounding each choice. One context corresponds to one choice and regroups every factor that might be different from one choice to another.\n",
    "\n",
    "\n",
    "From these two concepts, we defines 5 types of data:\n",
    "\n",
    "- **choices:** The main information, indicating which item/alternative has been chosen among all availables\n",
    "- **fixed_items_features:** The items features that never change (e.g. size, color, etc...) over the choices/contexts.\n",
    "  \n",
    "  Size=number of items.\n",
    "- **contexts_features:** It represents all the features that might change from one choice to another and that are **common** to all items (e.g. day of week, customer features, etc...).\n",
    "  \n",
    "  Size=number of choices.\n",
    "- **contexts_items_features:** The features that are function of the item and of the context (e.g. prices change over contexts and are specific to each sold item, etc...).\n",
    "  \n",
    "  Size=number of choices x number of items\n",
    "- **contexts_items_availabilities:** For each context it represents whether each item/alternative is proposed to the customer (1.) or not (0.).\n",
    "  \n",
    "  Size=number of choices.\n",
    "\n",
    "\n",
    "The easiest way to do it is to use a pandas DataFrame, let's see how to do it !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hands-on: example from a DataFrame with ModeCanada\n",
    "\n",
    "We will use the ModeCanada [1] dataset for this example. It is provided with the choice-learn package and can loaded as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "keep_output": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case</th>\n",
       "      <th>alt</th>\n",
       "      <th>choice</th>\n",
       "      <th>dist</th>\n",
       "      <th>cost</th>\n",
       "      <th>ivt</th>\n",
       "      <th>ovt</th>\n",
       "      <th>freq</th>\n",
       "      <th>income</th>\n",
       "      <th>urban</th>\n",
       "      <th>noalt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>28.25</td>\n",
       "      <td>50</td>\n",
       "      <td>66</td>\n",
       "      <td>4</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>car</td>\n",
       "      <td>1</td>\n",
       "      <td>83</td>\n",
       "      <td>15.77</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>28.25</td>\n",
       "      <td>50</td>\n",
       "      <td>66</td>\n",
       "      <td>4</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>car</td>\n",
       "      <td>1</td>\n",
       "      <td>83</td>\n",
       "      <td>15.77</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>28.25</td>\n",
       "      <td>50</td>\n",
       "      <td>66</td>\n",
       "      <td>4</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   case    alt  choice  dist   cost  ivt  ovt  freq  income  urban  noalt\n",
       "1     1  train       0    83  28.25   50   66     4    45.0      0      2\n",
       "2     1    car       1    83  15.77   61    0     0    45.0      0      2\n",
       "3     2  train       0    83  28.25   50   66     4    25.0      0      2\n",
       "4     2    car       1    83  15.77   61    0     0    25.0      0      2\n",
       "5     3  train       0    83  28.25   50   66     4    70.0      0      2"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from choice_learn.data import ChoiceDataset\n",
    "from choice_learn.datasets import load_modecanada\n",
    "\n",
    "canada_transport_df = load_modecanada(as_frame=True)\n",
    "canada_transport_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An extensive description of the dataset can be found [here](https://www.ssc.wisc.edu/~bhansen/econometrics/Koppelman_description.pdf).\n",
    "An extract indicates:\n",
    "\n",
    "\"The dataset was assembled in 1989 by VIA Rail (the Canadian national rail carrier) to estimate the demand for high-speed rail in the Toronto-Montreal corridor. The main information source was a Passenger Review administered to business travelers augmented by information about each trip. The observations consist of a choice between four modes of transportation (train, air, bus, car) with information about the travel mode and about the passenger. The posted dataset has been balanced to only include cases where all four travel modes are recorded. The file contains 11,116 observations on 2779 individuals.  \"\n",
    "\n",
    "Alright !\n",
    "If we go back to our dataframe, we can see the following columns:\n",
    "- case: an ID of the traveler\n",
    "- alt: the alternative concerned by the row\n",
    "- choice: 1 if the alternative was chosen, 0 otherwise\n",
    "- dist: trip distance\n",
    "- cost: trip cost\n",
    "- ivt: travel time in-vehicule (minutes)\n",
    "- ovt: travel time out-vehicule (minutes)\n",
    "- income: housold income of traveler ($)\n",
    "- urban: 1 if origin or destination is a large city\n",
    "- noalt: the number of alternative among which the traveler had to chose\n",
    "- freq: the frequence of the alternative (0 for car)\n",
    "\n",
    "Following our specification, we can see that one case corresponds to one customer thus one choice. In our choice-learn language it corresponds to \"one context\": a set of available alternatives and their features/specificites resulting in one choice.\n",
    "Let's regroup our features:\n",
    "\n",
    "**choices**\n",
    "Easy ! It is the alternative whenever the value is one.\n",
    "\n",
    "**contexts_features**\n",
    "The income, urban and distance (also noalt which is not really a feature) features are the same for all the alternative within a context: they are contexts_features. They are all constant with respect to a case=traveler ID.\n",
    "\n",
    "**contexts_items_features**\n",
    "Ivt, Ovt, cost and freq depends on the alternative and change over the contexts. They are contexts_items_features.\n",
    "\n",
    "**contexts_items_features**\n",
    "It in not directly indicated, however it can be easily deduced. Whenever an alternative is not available, it is not precised for its case. For example for the case=1, our first context, only train and car are given as alternatives, meaning that air and bus were could not be chosen/were not available.\n",
    "\n",
    "Okay, but we are missing fixed_items_features... Indeed there isn't really any in this dataset. Let's create one for the example.\n",
    "We will create is_public, indicating if an alternative is a public_transportation (1) or a private one (0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transport_df = canada_transport_df.copy()\n",
    "items = [\"air\", \"bus\", \"car\", \"train\"]\n",
    "\n",
    "# Add \"is_public\" feature for transport modes\n",
    "transport_df[\"is_public\"] = transport_df.apply(lambda row: 0. if row.alt == \"car\" else 1., axis=1)\n",
    "\n",
    "# Just some typing\n",
    "transport_df.income = transport_df.income.astype(\"float32\")\n",
    "\n",
    "# Let's take a look at our new df:\n",
    "transport_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our feature, is_public is 0 for the car and 1 for all other alternatives, seems fine! We can now create our ChoiceDataset !\\\n",
    "*Note that you do NOT need each type of feature, here the purpose was to give a complete example.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a ChoiceDataset from this *single* dataframe\n",
    "\n",
    "In order to create the ChoiceDataset from the DataFrame, we need to specify:\n",
    "- the column in which the choice is given\n",
    "- the column where the item is identified \n",
    "- the column where the context is identified\n",
    "- the columns representing the fixed_items_features\n",
    "- the columns representing the contexts_features\n",
    "- the columns representing the contexts_items_features\n",
    "\n",
    "\n",
    "For our Canada Transport example, here is how it should be done:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ChoiceDataset.from_single_long_df(\n",
    "    df=transport_df,\n",
    "    choices_column=\"choice\",\n",
    "    items_id_column=\"alt\",\n",
    "    contexts_id_column=\"case\",\n",
    "    fixed_items_features_columns=[\"is_public\"],\n",
    "    contexts_features_columns=[\"income\", \"urban\", \"dist\"],\n",
    "    contexts_items_features_columns=[\"cost\", \"freq\", \"ovt\", \"ivt\"],\n",
    "    choice_format=\"one_zero\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last argument, \"choice_format\", precises how the choice is encoded in the dataframe. Currently two modes are availble:\n",
    "\n",
    " - *one_zero*:\n",
    "The choice column contains a 0 when the alternative/item is not chosen in the session and a 1 if it is chosen.\n",
    "This is the case here with Canada Transport.\n",
    " - *item_id*:\n",
    "The choice column contains the id of the choice during the session. The id corresponds to the values used in the column 'items_id_column'.\n",
    "In this case of Canada Transport, the dataframe would need to be:\n",
    "\n",
    "| | case | alt | choice | dist | cost | ivt | ovt | freq | \tincome | urban | noalt | \n",
    "|---|---|---|---|---|---|---|---|---|---|---|---|\n",
    "| 1 | 1 | train | car | 83 | 28.25 | 50 | 66 | 4 | 45 | 0 | 2 |\n",
    "| 2 | 1 | car | car | 83 | 15.77 | 61 | 0 | 0 | 45 | 0 | 2 |\n",
    "| 3 | 2 | train | car | 83 | 28.25 | 50 | 66 | 4 | 25 | 0 | 2 |\n",
    "| 4 | 2 | car | car | 83 | 15.77 | 61 | 0 | 0 | 25 | 0 | 2 |\n",
    "| 5 | 3 | train | car | 83 | 28.25 | 50 | 66 | 4 | 70 | 0 | 2 |\n",
    "\n",
    "In the first 5 examples, the chosen transportation is always the car."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ChoiceDataset is ready !\n",
    "\n",
    "If your DataFrame is in the wide format, you can use the equivalent method *from_single_wide_df*. An example can be found [here](https://github.com/artefactory/choice-learn-private/blob/main/notebooks/dataset_creation.ipynb) on the SwissMetro dataset: \n",
    "\n",
    "You now have three possibilities to continue discovering the choice-learn package:\n",
    "- You can directly go [here]() to the modelling tutorial if you want to understand how a first simple ConditionMNl would be implemented.\n",
    "- You can go [here]() if your dataset is organized differently to see all the different ways to instantiate a ChoiceDataset. In particular it helps if you data is splitted into several DataFrames or if you have another format of data.\n",
    "- Or you can continue this current tutorial to better understand the ChoiceDataset machinery and everything there is to know about it.\n",
    "\n",
    "Whatever your choice, you can also check [here](#ready-to-use-datasets) the list of open source datasets available directly with the package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hands-on: example from a NumPy arrays\n",
    "\n",
    "Let's see an example of ChoiceDataset instantiation from numpy arrays.\n",
    "\n",
    "Let's consider three *items* whose *features* are: Size, Weight, price, promotion (simply a boolean to indicate whether it is under promotion).\n",
    "\n",
    "For size and weights, we will store as *fixed items features* as they don't change. For the price and promotion, we will store in the *contexts items features*, since they may change for each context.\n",
    "\n",
    "For the *contexts*, we will consider the customers attributes: Budget and age."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choices:\n",
    "# Customer 1 bought item 1\n",
    "# Customer 2 bought item 3\n",
    "# Customer 1 bought item 2\n",
    "\n",
    "choices = [0, 2, 1]\n",
    "\n",
    "fixed_items_features = [\n",
    "    [1, 2], # item 1 [size, weight]\n",
    "    [2, 4], # item 2 [size, weight]\n",
    "    [1.5, 1.5], # item 3 [size, weight]\n",
    "]\n",
    "\n",
    "contexts_features = [\n",
    "    [100, 20], # choice 1, customer 1 [budget, age]\n",
    "    [200, 40], # choice 2, customer 2 [budget, age]\n",
    "    [80, 20], # choice 3, customer 1 [budget, age]\n",
    "]\n",
    "\n",
    "contexts_items_features = [\n",
    "    [\n",
    "        [100, 0], # choice 1, Item 1 [price, promotion]\n",
    "        [140, 0], # choice 1, Item 2 [price, promotion]\n",
    "        [200, 0], # choice 1, Item 2 [price, promotion]\n",
    "    ],\n",
    "    [\n",
    "        [100, 0], # choice 2, Item 1 [price, promotion]\n",
    "        [120, 1], # choice 2, Item 2 [price, promotion]\n",
    "        [200, 0], # choice 2, Item 2 [price, promotion]\n",
    "    ],\n",
    "    [\n",
    "        [100, 0], # choice 3, Item 1 [price, promotion]\n",
    "        [120, 1], # choice 3, Item 2 [price, promotion]\n",
    "        [180, 1], # choice 3, Item 2 [price, promotion]\n",
    "    ],\n",
    "]\n",
    "\n",
    "contexts_items_availabilities = [\n",
    "    [1, 1, 1], # All items available at choice 1\n",
    "    [1, 1, 1], # All items available at choice 2\n",
    "    [0, 1, 1], # Item 1 not available at choice 3\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in items_features and contexts_items_features, the features need to be well ordered:\n",
    "- The features are ordered the same for all items\n",
    "- The items are ordered in their index given in choices. This applies in items_features and contexts_items_features\n",
    "\n",
    "\n",
    "**items_features** = [[item1_featureA, item1_featureB, ...], [item2_featureA, item2_featureB, ...], ...]\n",
    "\n",
    "**contexts_items_features** = [[[context1_item1_featureA, ...], [context1_item2_featureA, ...]], [[context2_item1_featureA, ...], [context2_item2_featureA, ...]], ...]\n",
    "\n",
    "**choices** then represent the index of the item: 0 when item1 is chose, 1 when item2, etc..., e.g. [0, 0, 2, 1, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ChoiceDataset(\n",
    "    choices=choices,\n",
    "    fixed_items_features=fixed_items_features,\n",
    "    fixed_items_features_names=[\"size\", \"weight\"], # You can precise the names of the features if you want\n",
    "    contexts_features=contexts_features,\n",
    "    contexts_features_names=[\"budget\", \"age\"], # same, not mandatory\n",
    "    contexts_items_features=contexts_items_features,\n",
    "    contexts_items_features_names=[\"price\", \"promotion\"], # same, not mandatory\n",
    "    contexts_items_availabilities=contexts_items_availabilities,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "keep_output": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3, 2)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.contexts_items_features[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ChoiceDataset is indexed by choice. You can use [] to subset it.\n",
    "It is particularly useful for train/test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "keep_output": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some choices never happen in the dataset: {1}\n",
      "Some choices never happen in the dataset: {0, 2}\n",
      "Train Dataset length: 2 Test Dataset lenght: 1\n"
     ]
    }
   ],
   "source": [
    "train_index = [0, 1]\n",
    "test_index = [2]\n",
    "train_dataset = dataset[train_index]\n",
    "test_dataset = dataset[test_index]\n",
    "print(\"Train Dataset length:\", len(train_dataset), \"Test Dataset lenght:\", len(test_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to access the features you can use the .iloc function with choices indexes \n",
    "It returns the features in this order:\n",
    "\n",
    "- items_features (n_items, n_items_features)\n",
    "- contexts_features (n_choices, n_sessions_features)\n",
    "- contexts_items_features (n_choices, n_items, n_sessions_items_features)\n",
    "- contexts_items_availabilities (n_choices, n_items)\n",
    "- choices (n_choices,)\n",
    "\n",
    "As a reminder, we have as many contexts as we have choices in the dataset !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| index | feature  | shape  |   \n",
    "|---|---|---|\n",
    "| 0 | items_features | (n_items, n_items_features) |\n",
    "| 1 | contexts_features | (n_choices, n_contexts_features) |\n",
    "| 2 | contexts_items_features | (n_choices, n_items, n_contexts_items_features) |\n",
    "| 3 | context_items_availabilities | (n_choices, n_items) |\n",
    "| 4 | choices | (n_choices,) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "keep_output": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Items features: (array([[1. , 2. ],\n",
      "       [2. , 4. ],\n",
      "       [1.5, 1.5]], dtype=float32),)\n",
      "Contexts features: (array([[100,  20],\n",
      "       [200,  40]], dtype=int32),)\n",
      "Contexts Items features: (array([[[100,   0],\n",
      "        [140,   0],\n",
      "        [200,   0]],\n",
      "\n",
      "       [[100,   0],\n",
      "        [120,   1],\n",
      "        [200,   0]]], dtype=int32),)\n",
      "Contexts Items Availabilities features: [[1. 1. 1.]\n",
      " [1. 1. 1.]]\n",
      "Contexts Choices: [0 2]\n"
     ]
    }
   ],
   "source": [
    "contexts_indexes = [0, 1]\n",
    "print(\"Items features:\", train_dataset.batch[contexts_indexes][0])\n",
    "print(\"Contexts features:\", train_dataset.batch[contexts_indexes][1])\n",
    "print(\"Contexts Items features:\", train_dataset.batch[contexts_indexes][2])\n",
    "print(\"Contexts Items Availabilities features:\", train_dataset.batch[contexts_indexes][3])\n",
    "print(\"Contexts Choices:\", train_dataset.batch[contexts_indexes][4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To simplify the iteration over the dataset you can call the .iter_batch method, with the batch_size argument.\n",
    "\n",
    "Note that batch_size=-1 returns the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "keep_output": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (array([[1. , 2. ],\n",
      "       [2. , 4. ],\n",
      "       [1.5, 1.5]], dtype=float32), array([[100,  20]], dtype=int32), array([[[100,   0],\n",
      "        [140,   0],\n",
      "        [200,   0]]], dtype=int32), array([[1., 1., 1.]], dtype=float32), array([0], dtype=int32))\n",
      "1 (array([[1. , 2. ],\n",
      "       [2. , 4. ],\n",
      "       [1.5, 1.5]], dtype=float32), array([[200,  40]], dtype=int32), array([[[100,   0],\n",
      "        [120,   1],\n",
      "        [200,   0]]], dtype=int32), array([[1., 1., 1.]], dtype=float32), array([2], dtype=int32))\n",
      "2 (array([[1. , 2. ],\n",
      "       [2. , 4. ],\n",
      "       [1.5, 1.5]], dtype=float32), array([[80, 20]], dtype=int32), array([[[100,   0],\n",
      "        [120,   1],\n",
      "        [180,   1]]], dtype=int32), array([[0., 1., 1.]], dtype=float32), array([1], dtype=int32))\n"
     ]
    }
   ],
   "source": [
    "# All the features are given for each session, in order to compute utility and NegativeLogLikelihood\n",
    "for i, batch in enumerate(dataset.iter_batch(batch_size=1)):\n",
    "    print(i, batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stacking features when building the ChoiceDataset**\n",
    "\n",
    "If you need to keep a clear distinction between different features, you can use stacking in the ChoiceDataset. In this case, you need to provide the additional features arrays indexed the same. It is possible to stack: *items_features*, *contexts_features*, *contexts_items_features*.\n",
    "\n",
    "For example if we have two kind of items_features and we do not want them to be within the same np.ndarray we can as follow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_features_2 = [\n",
    "    [11, 12], # item 1 \n",
    "    [12, 14], # item 2 \n",
    "    [11.5, 11.5], # item 3 \n",
    "]\n",
    "dataset = ChoiceDataset(\n",
    "    # Here items_features specified as a tuple of the two features lists\n",
    "    fixed_items_features=(fixed_items_features, items_features_2),\n",
    "    contexts_features=contexts_features,\n",
    "    contexts_items_features=contexts_items_features,\n",
    "    contexts_items_availabilities=contexts_items_availabilities,\n",
    "    choices=choices,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When indexing or batching your ChoiceDataset, you will now get items_features as a tuple, with elements corresponding to (items_features, items_features_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "keep_output": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([[1. , 2. ],\n",
       "         [2. , 4. ],\n",
       "         [1.5, 1.5]], dtype=float32),\n",
       "  array([[11. , 12. ],\n",
       "         [12. , 14. ],\n",
       "         [11.5, 11.5]], dtype=float32)),\n",
       " array([100,  20], dtype=int32),\n",
       " array([[100,   0],\n",
       "        [140,   0],\n",
       "        [200,   0]], dtype=int32),\n",
       " array([1, 1, 1], dtype=object),\n",
       " 0)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.batch[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Advanced use: the FeatureStorage & RAM optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FeaturesStorage, why should I use it ?\n",
    "Regularly, you have features that repeat themselves over several choices. It can happen if you have several times the same customer, if you have store features or if you use OneHot representations... And those are only example.\n",
    "\n",
    "The FeaturesStorage object is designed to help you better handle these cases. It is mainly built to work well with ChoiceDataset, but here is a small introduction on how it works:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's consider a case where we consider three supermarkets: \n",
    "- supermarket_1 with surface of 100 and 250 average nb of customers\n",
    "- supermarket_2 with surface of 150 and 500 average nb of customers\n",
    "- supermarket_3 with surface of 80 and 100 average nb of customers \n",
    "\n",
    "In each store, we have 4 available products for which we have little information. For the example'sake, let's consider the following utility:\n",
    "$$U(i) = u_i + \\beta_1 \\cdot S_s + \\beta_2 \\cdot C_s$$\n",
    "With $S_s$ the surface of the store and $C_s$ its average number of customers.\n",
    "\n",
    "We want to estimate the base utilities $u_i$ and the two coefficients: $\\beta_1$ and $\\beta_2$.\n",
    "\n",
    "Let's start with creating a ChoiceDataset without the FeaturesStorage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "keep_output": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usual Supermakerket Features Shape: (18, 2)\n"
     ]
    }
   ],
   "source": [
    "# Here are our choices:\n",
    "choices = [0, 1, 2, 0, 2, 1, 1, 0, 2, 1, 2, 0, 2, 0, 1, 2, 1, 0]\n",
    "supermarket_features = [[100, 250], [150, 500], [80, 100]]\n",
    "# Now our store sequence of supermarkets is:\n",
    "supermarkets_sequence = [1, 1, 2, 3, 2, 1, 2, 1, 1, 2, 3, 2, 1, 2, 2, 3, 1, 2]\n",
    "\n",
    "# The usual way to store the features would be to create the contexts_features array that contains\n",
    "# the right features:\n",
    "usual_supermarket_features = np.array([supermarket_features[supermarket_id - 1] for supermarket_id in supermarkets_sequence])\n",
    "print(\"Usual Supermakerket Features Shape:\", usual_supermarket_features.shape)\n",
    "\n",
    "# And now we can create our ChoiceDataset:\n",
    "\n",
    "usual_dataset = ChoiceDataset(choices=choices,\n",
    "                              fixed_items_features=np.eye(3),\n",
    "                              contexts_features=usual_supermarket_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have our dataset, we only need to create our ChoiceModel and we are good to go. However, it would also be natural to feel unsatisfied because your dataset is not well optimized. Indeed we have repeated the same information several times having a lot of redundant information.\n",
    "\n",
    "If in our small use-case it does not really matter, if we consider hundreds of stores on several millions - or billions - of choices, it would become... unreasonable!\n",
    "\n",
    "Let's now welcome the FeaturesStorage to help us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from choice_learn.data import FeaturesStorage\n",
    "\n",
    "features_dict = {f\"supermarket_{i+1}\": supermarket_features[i] for i in range(3)}\n",
    "storage = FeaturesStorage(values=features_dict, name=\"supermarket_features\")\n",
    "\n",
    "# Let's see how we can use this bad boy:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The FeaturesStorage is basically a Python dictionnary with a wrap-up to easily get batches of data.\\\n",
    "You can ask for a sequence of features with .batch. It works with the keys of our dictionnary that can be int, float, str, etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "keep_output": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving features of first supermarket:\n",
      "[100 250]\n",
      "Retrieving a batch of features:\n",
      "[[100 250]\n",
      " [150 500]\n",
      " [100 250]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Retrieving features of first supermarket:\")\n",
    "print(storage.batch[\"supermarket_1\"])\n",
    "print(\"Retrieving a batch of features:\")\n",
    "print(storage.batch[[\"supermarket_1\", \"supermarket_2\", \"supermarket_1\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The FeaturesStorage is handy for its transparent use with ChoiceDataset. For it to work well you need:\n",
    "- to specify a FeaturesStorage name\n",
    "- to match FeaturesStorage ids with the sequence\n",
    "\n",
    "In our case we call our FeaturesStorage \"supermarket_features\", the ids are now strings, let's maker the sequence match:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_supermarkets_sequence = [[f\"supermarket_{i}\"] for i in supermarkets_sequence]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we can create our ChoiceDataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_dataset = ChoiceDataset(choices=choices,\n",
    "                                contexts_features=str_supermarkets_sequence,\n",
    "                                contexts_features_names=[\"supermarket_features\"],\n",
    "                                fixed_items_features=np.eye(3),\n",
    "                                features_by_ids=[storage],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have paid attention, we have specified the FeaturesStorage in the features_by_ids argument and we HAVE TO match the contexts_features_names column with the name of the Features Storage.\\\n",
    "When calling for a batch of data, the ChoiceDataset will look into the FeaturesStorage call \"supermarket_features\" to match the values in contexts_features with the ones store in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "keep_output": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Fixed Items Features: [[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]]\n",
      "Batch Contexts Features: [100 250]\n",
      "Batch Choice: 0\n",
      "%-------------------------%\n",
      "Batch Fixed Items Features: [[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]]\n",
      "Batch Contexts Features: [[100 250]\n",
      " [150 500]\n",
      " [ 80 100]]\n",
      "Batch Choice: [1 2 0]\n",
      "%-------------------------%\n",
      "Batch Fixed Items Features: [[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]]\n",
      "Batch Contexts Features: [[100 250]\n",
      " [100 250]\n",
      " [100 250]]\n",
      "Batch Choice: [0 1 1]\n"
     ]
    }
   ],
   "source": [
    "batch = storage_dataset.batch[0]\n",
    "print(\"Batch Fixed Items Features:\", batch[0])\n",
    "print(\"Batch Contexts Features:\", batch[1])\n",
    "print(\"Batch Choice:\", batch[4])\n",
    "print(\"%-------------------------%\")\n",
    "batch = storage_dataset.batch[[1, 2, 3]]\n",
    "print(\"Batch Fixed Items Features:\", batch[0])\n",
    "print(\"Batch Contexts Features:\", batch[1])\n",
    "print(\"Batch Choice:\", batch[4])\n",
    "print(\"%-------------------------%\")\n",
    "batch = storage_dataset.batch[[0, 1, 5]]\n",
    "print(\"Batch Fixed Items Features:\", batch[0])\n",
    "print(\"Batch Contexts Features:\", batch[1])\n",
    "print(\"Batch Choice:\", batch[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything is mapped as needed. And the great thing is that you can easily mix ''classical'' features with FeaturesStorages.\\\n",
    "Let's add a 'is_week_end' feature to our problem that will also be stored as a contexts_features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "keep_output": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>supermarket_features</th>\n",
       "      <th>is_week_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>supermarket_1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>supermarket_1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>supermarket_2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>supermarket_3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>supermarket_2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  supermarket_features  is_week_end\n",
       "0        supermarket_1            0\n",
       "1        supermarket_1            0\n",
       "2        supermarket_2            0\n",
       "3        supermarket_3            1\n",
       "4        supermarket_2            1"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contexts_features = pd.DataFrame({\"supermarket_features\": np.array(str_supermarkets_sequence).squeeze(),\n",
    "\"is_week_end\": [0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0]})\n",
    "contexts_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation of the ChoiceDataset\n",
    "storage_dataset = ChoiceDataset(choices=choices,\n",
    "                                contexts_features=contexts_features,\n",
    "                                fixed_items_features=np.eye(3),\n",
    "                                features_by_ids=[storage],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "keep_output": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Fixed Items Features: [[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]]\n",
      "Batch Contexts Features: [[100 250   0]\n",
      " [150 500   0]\n",
      " [ 80 100   1]]\n",
      "Batch Choice: [1 2 0]\n"
     ]
    }
   ],
   "source": [
    "# And now it's ready\n",
    "batch = storage_dataset.batch[[1, 2, 3]]\n",
    "print(\"Batch Fixed Items Features:\", batch[0])\n",
    "print(\"Batch Contexts Features:\", batch[1])\n",
    "print(\"Batch Choice:\", batch[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specific sub-example: the OneHot Storage\n",
    "A recurring usecase is the use of **OneHot** representation of features. The OneHotStorage is built specifically for one-hot encoded features and further improves memory consumption. The storage is to be used the same way as FeaturesStorage, but behind will only keep the index of the one of each element and will consitute the one-hot vector only when needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from choice_learn.data import OneHotStorage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "keep_output": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAM storage of the OneHotStore: {'a': 0, 'b': 1, 'c': 2}\n",
      "One-hot vector batch: storage.batch['a'] [1 0 0]\n",
      "One-hot vector batch: storage.batch[['a', 'b', 'c', 'c', 'b', 'a']]\n",
      "[[1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "storage = OneHotStorage(ids=[\"a\", \"b\", \"c\"])\n",
    "\n",
    "print(\"RAM storage of the OneHotStore:\", storage.storage)\n",
    "# When indexing with .batch, we can access the one-hot encoding of the element using its id\n",
    "print(\"One-hot vector batch: storage.batch['a']\", storage.batch[\"a\"])\n",
    "print(\"One-hot vector batch: storage.batch[['a', 'b', 'c', 'c', 'b', 'a']]\")\n",
    "print(storage.batch[[\"a\", \"b\", \"c\", \"c\", \"b\", \"a\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note that:**\n",
    "- we use strings as ids for the example, however we recommend to use integers.\n",
    "- FeaturesStorage can be instantiated from dict, np.ndarray, list, pandas.DataFrame, etc...\n",
    "- More in-depth examples and explanations can be found [here](./features_byID_example.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ready-to-use datasets\n",
    "A few well-known open source datasets are directly integrated and the package and can be downloaded in one line:\n",
    "- SwissMetro from Bierlaire et al (2001) [2]\n",
    "- ModeCanada from Koppleman et al. (1993) [1]\n",
    "- The Train dataset from Ben Akiva et al. (1993) [4]\n",
    "- The Heating & Electricity datasets from Kenneth Train [3]\n",
    "- The TaFeng dataset from Kaggle [5]\n",
    "\n",
    "If you feel like another open-source dataset should be included, reach out !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from choice_learn.datasets import load_swissmetro, load_modecanada, load_train, load_heating, load_electricity, load_tafeng\n",
    "\n",
    "canada_choice_dataset = load_modecanada()\n",
    "swissmetro_choice_dataset = load_swissmetro()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The datasets can also be downloaded as dataframes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "keep_output": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GROUP</th>\n",
       "      <th>SURVEY</th>\n",
       "      <th>SP</th>\n",
       "      <th>ID</th>\n",
       "      <th>PURPOSE</th>\n",
       "      <th>FIRST</th>\n",
       "      <th>TICKET</th>\n",
       "      <th>WHO</th>\n",
       "      <th>LUGGAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>...</th>\n",
       "      <th>TRAIN_CO</th>\n",
       "      <th>TRAIN_HE</th>\n",
       "      <th>SM_TT</th>\n",
       "      <th>SM_CO</th>\n",
       "      <th>SM_HE</th>\n",
       "      <th>SM_SEATS</th>\n",
       "      <th>CAR_TT</th>\n",
       "      <th>CAR_CO</th>\n",
       "      <th>CHOICE</th>\n",
       "      <th>CAR_HE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>48.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>48.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>48.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>40.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>36.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   GROUP  SURVEY   SP   ID  PURPOSE  FIRST  TICKET  WHO  LUGGAGE  AGE  ...  \\\n",
       "0    2.0     0.0  1.0  1.0      1.0    0.0     1.0  1.0      0.0  3.0  ...   \n",
       "1    2.0     0.0  1.0  1.0      1.0    0.0     1.0  1.0      0.0  3.0  ...   \n",
       "2    2.0     0.0  1.0  1.0      1.0    0.0     1.0  1.0      0.0  3.0  ...   \n",
       "3    2.0     0.0  1.0  1.0      1.0    0.0     1.0  1.0      0.0  3.0  ...   \n",
       "4    2.0     0.0  1.0  1.0      1.0    0.0     1.0  1.0      0.0  3.0  ...   \n",
       "\n",
       "   TRAIN_CO  TRAIN_HE  SM_TT  SM_CO  SM_HE  SM_SEATS  CAR_TT  CAR_CO  CHOICE  \\\n",
       "0      48.0     120.0   63.0   52.0   20.0       0.0   117.0    65.0     2.0   \n",
       "1      48.0      30.0   60.0   49.0   10.0       0.0   117.0    84.0     2.0   \n",
       "2      48.0      60.0   67.0   58.0   30.0       0.0   117.0    52.0     2.0   \n",
       "3      40.0      30.0   63.0   52.0   20.0       0.0    72.0    52.0     2.0   \n",
       "4      36.0      60.0   63.0   42.0   20.0       0.0    90.0    84.0     2.0   \n",
       "\n",
       "   CAR_HE  \n",
       "0     0.0  \n",
       "1     0.0  \n",
       "2     0.0  \n",
       "3     0.0  \n",
       "4     0.0  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swissmetro_df = load_swissmetro(as_frame=True)\n",
    "swissmetro_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "[1] Koppelman et al. (1993), *Application and Interpretation of Nested Logit Models of Intercity Mode Choice*\\\n",
    "[2] Bierlaire, M., Axhausen, K. and Abay, G. (2001), *The Acceptance of Modal Innovation: The Case of SwissMetro*\\\n",
    "[3] Train, K.E. (2003) *Discrete Choice Methods with Simulation.* Cambridge University Press.\\\n",
    "[4] Ben-Akiva M.; Bolduc D.; Bradley M. (1993) *Estimation of Travel Choice Models with Randomly Distributed Values of Time*\\\n",
    "[5] https://www.kaggle.com/datasets/chiranjivdas09/ta-feng-grocery-dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
