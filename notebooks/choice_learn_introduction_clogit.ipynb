{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to choice-learn's modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Started with the ConditionalMNL\n",
    "\n",
    "The choice-learn package offers a high level API to conceive and estimate discrete choice models. Several models are ready to be used, you can check the list [here](../README.md). If you want to create your own model or another one that is not in the list, the lower level API can help you. Check the notebook [here](./custom_model.ipynb).\n",
    "\n",
    "We begin this tutorial with the estimation of a Conditional Logit Model on the ModeCanada dataset[1]. We try to reproduce the example [Torch-Choice](https://gsbdbi.github.io/torch-choice/conditional_logit_model_mode_canada/).\n",
    "We also reproduce the example from [PyLogit](https://github.com/timothyb0912/pylogit/blob/master/examples/notebooks/Main%20PyLogit%20Example.ipynb) [here](#example-2-swissmetro).\n",
    "\n",
    "First, we download our data as a ChoiceDataset. See the [data management tutorial](./choice_learn_introduction_data.ipynb) first if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from choice_learn.datasets import load_modecanada\n",
    "\n",
    "transport_df = load_modecanada(as_frame=True)\n",
    "\n",
    "# Following torch-choice guide:\n",
    "transport_df = transport_df.loc[transport_df.noalt == 4]\n",
    "\n",
    "items = [\"air\", \"bus\", \"car\", \"train\"]\n",
    "\n",
    "transport_df[\"oh_air\"] = transport_df.apply(lambda row: 1. if row.alt == items[0] else 0., axis=1)\n",
    "transport_df[\"oh_bus\"] = transport_df.apply(lambda row: 1. if row.alt == items[1] else 0., axis=1)\n",
    "transport_df[\"oh_car\"] = transport_df.apply(lambda row: 1. if row.alt == items[2] else 0., axis=1)\n",
    "transport_df[\"oh_train\"] = transport_df.apply(lambda row: 1. if row.alt == items[3] else 0., axis=1)\n",
    "\n",
    "transport_df.income = transport_df.income.astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization of the ChoiceDataset\n",
    "from choice_learn.data import ChoiceDataset\n",
    "dataset = ChoiceDataset.from_single_df(df=transport_df,\n",
    "                                       fixed_items_features_columns=[\"oh_air\", \"oh_bus\", \"oh_car\", \"oh_train\"],\n",
    "                                       contexts_features_columns=[\"income\"],\n",
    "                                       contexts_items_features_columns=[\"cost\", \"freq\", \"ovt\", \"ivt\"],\n",
    "                                       items_id_column=\"alt\",\n",
    "                                       contexts_id_column=\"case\",\n",
    "                                       choices_column=\"choice\",\n",
    "                                       choice_mode=\"one_zero\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can import the model from choice_learn.models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from choice_learn.models import ConditionalMNL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The conditional MNL[2] specifies a linear utility for each item i during the session s with regards to the features:\n",
    "$$\n",
    "U(i, s) = \\sum_{features} a(i, s) * feat(i, s)\n",
    "$$\n",
    "\n",
    "We will use a ModelSpecification object to define our model with regards to our ChoiceDataset.\n",
    "For each feature in the choice dataset we can specify how it must be specified in the utility.\n",
    "\n",
    "Let's re-use a common example from on the ModeCanda[1] dataset:\n",
    "$$\n",
    "U(i, s) = \\beta^{inter}_i + \\beta^{price} \\cdot price(i, s) + \\beta^{freq} \\cdot freq(i, s) + \\beta^{ovt} \\cdot ovt(i, s) + \\beta^{income}_i \\cdot income(s) + \\beta^{ivt}_i \\cdot ivt(i, t) + \\epsilon(i, t)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we want to estimate:\n",
    "\n",
    "- one $\\beta^{price}$, $\\beta^{freq}$ and $\\beta^{ovt}$ coefficient. They are shared by all items.\n",
    "- one $\\beta^{ivt}$ coefficient for **each** item.\n",
    "- one $\\beta^{inter}$ and $\\beta^{income}$ coefficient for **each** item, with **additional constraint** to be 0 for the first item (air).\n",
    "\n",
    "We will use a ModelSpecification object to create the right utility function.\n",
    "We need to specify for each weight:\n",
    "- a unique name\n",
    "- the name of the feature it goes with:\n",
    "    - it must match the feature name in the ChoiceDataset\n",
    "    - \"intercept\" is the standardized name used for intercept, pay attention not to override it\n",
    "- items_indexes: the items concerned, as indexed in the ChoiceDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization of the model\n",
    "model = ConditionalMNL(optimizer=\"lbfgs\")\n",
    "\n",
    "# Creation of the different weights:\n",
    "\n",
    "\n",
    "# add_coefficients adds one coefficient for each specified item_index\n",
    "# intercept, and income are added for each item except the first one that needs to be zeroed\n",
    "model.add_coefficients(coefficient_name=\"beta_inter\", feature_name=\"intercept\", items_indexes=[1, 2, 3])\n",
    "model.add_coefficients(coefficient_name=\"beta_income\", feature_name=\"income\", items_indexes=[1, 2, 3])\n",
    "\n",
    "# ivt is added for each item:\n",
    "model.add_coefficients(coefficient_name=\"beta_ivt\", feature_name=\"ivt\", items_indexes=[0, 1, 2, 3])\n",
    "\n",
    "# shared_coefficient add one coefficient that is used for all items specified in the items_indexes:\n",
    "# Here, cost, freq and ovt coefficients are shared between all items\n",
    "model.add_shared_coefficient(coefficient_name=\"beta_cost\", feature_name=\"cost\", items_indexes=[0, 1, 2, 3])\n",
    "model.add_shared_coefficient(coefficient_name=\"beta_freq\", feature_name=\"freq\", items_indexes=[0, 1, 2, 3])\n",
    "model.add_shared_coefficient(coefficient_name=\"beta_ovt\", feature_name=\"ovt\", items_indexes=[0, 1, 2, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can instantiate our ConditionalMNL from the specification. We use LBFGS as the estimation method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to estimate the the coefficients values, use the .fit method with the ChoiceDataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(dataset, n_epochs=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is possible to see the estimated coefficients with the .weights argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The negative loglikelihood can be estimated using .evaluate():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "keep_output": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average neg-loglikelihood is: 0.674474\n",
      "The total neg-loglikelihood is: 1874.3632485866547\n"
     ]
    }
   ],
   "source": [
    "print(\"The average neg-loglikelihood is:\", model.evaluate(dataset).numpy())\n",
    "print(\"The total neg-loglikelihood is:\", model.evaluate(dataset).numpy()*len(dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A faster specification can be done using a dictionnary. It follows torch-choice \\ref{} method to create conditional logit models.\n",
    "The parameters dict needs to be as follows:\n",
    "- The key is the feature name\n",
    "- The value is the mode. Currently three modes are available:\n",
    "    - constant: the learned coefficient is shared by all items\n",
    "    - item: one coefficient by item is estimated, the value for the item at index 0 is set to 0\n",
    "    - item-full: one coefficient by item is estimated\n",
    "\n",
    "In order to create the same model for the ModeCanada dataset, it looks as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "keep_output": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using L-BFGS optimizer, setting up .fit() function\n"
     ]
    }
   ],
   "source": [
    "# Instantiation of the parameters dictionnary\n",
    "params = {\"income\": \"item\",\n",
    " \"cost\": \"constant\", \n",
    " \"freq\": \"constant\",\n",
    " \"ovt\": \"constant\", \n",
    " \"ivt\": \"item-full\",\n",
    " \"intercept\": \"item\"}\n",
    "\n",
    "# Instantiation of the model\n",
    "cmnl = ConditionalMNL(parameters=params, optimizer=\"lbfgs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = cmnl.fit(dataset, n_epochs=1000)\n",
    "print(cmnl.weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compare the estimated coefficients and the negative log-likelihood obtained in \\ref{} and \\ref{torch-choice}, and it is similar !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "keep_output": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature oh_air is in dataset but has no weight assigned in utility                            computations\n",
      "Feature oh_bus is in dataset but has no weight assigned in utility                            computations\n",
      "Feature oh_car is in dataset but has no weight assigned in utility                            computations\n",
      "Feature oh_train is in dataset but has no weight assigned in utility                            computations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Ground Truth' Negative LogLikelihood: tf.Tensor(1874.3633, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Here are the values obtained in the references:\n",
    "gt_weights = [\n",
    "    tf.constant([[-0.0890796, -0.0279925, -0.038146]]),\n",
    "    tf.constant([[-0.0333421]]),\n",
    "    tf.constant([[0.0925304]]),\n",
    "    tf.constant([[-0.0430032]]),\n",
    "    tf.constant([[0.0595089, -0.00678188, -0.00645982, -0.00145029]]),\n",
    "    tf.constant([[0.697311, 1.8437, 3.27381]]),\n",
    "]\n",
    "gt_model = ConditionalMNL(parameters=params, lr=0.01)\n",
    "gt_model.fit(dataset, n_epochs=1, batch_size=-1)\n",
    "\n",
    "# Here we estimate the negative log-likelihood with these coefficients (also, we obtain same value as in those papers):\n",
    "gt_model.weights = gt_weights\n",
    "print(\"'Ground Truth' Negative LogLikelihood:\", gt_model.evaluate(dataset) * len(dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to estimate the utilities, use the .predict_utility() method. In order to estimate the probabilities, use the .compute_probabilities() method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "keep_output": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Purchase probability of each item for the first 5 sessions: tf.Tensor(\n",
      "[[0.1906135  0.00353266 0.4053667  0.4004831 ]\n",
      " [0.34869286 0.00069682 0.36830992 0.28229675]\n",
      " [0.14418365 0.00651285 0.40567666 0.44362238]\n",
      " [0.34869286 0.00069682 0.36830992 0.28229675]\n",
      " [0.34869286 0.00069682 0.36830992 0.28229675]], shape=(5, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# print(\"Utilities of each item for the first 5 sessions:\", cmnl.predict_utility(dataset)[:5])\n",
    "print(\"Purchase probability of each item for the first 5 sessions:\", cmnl.predict_probas(dataset)[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For very large datasets that do not fit entirely in the memory, the LBFGS method might not be the best choice. Here we can use the power of the Tensorflow library to use stochastic gradient descent optimizers.\n",
    "\n",
    "In this case, it is possible to obtain the same coefficients estimation, also it is a little tricky to get it quickly. We need to adjust the learning rate over time for the optimization not to be too slow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmnl = ConditionalMNL(parameters=params, optimizer=\"Adam\")\n",
    "history = cmnl.fit(dataset, n_epochs=2000, batch_size=-1)\n",
    "cmnl.optimizer.lr = cmnl.optimizer.lr / 5\n",
    "history2 = cmnl.fit(dataset, n_epochs=4000, batch_size=-1)\n",
    "cmnl.optimizer.lr = cmnl.optimizer.lr  / 10\n",
    "history3 = cmnl.fit(dataset, n_epochs=20000, batch_size=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "keep_output": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'income:0' shape=(1, 3) dtype=float32, numpy=array([[-0.08402912, -0.02359904, -0.03233582]], dtype=float32)>,\n",
       " <tf.Variable 'cost:0' shape=(1, 1) dtype=float32, numpy=array([[-0.05140894]], dtype=float32)>,\n",
       " <tf.Variable 'freq:0' shape=(1, 1) dtype=float32, numpy=array([[0.09645303]], dtype=float32)>,\n",
       " <tf.Variable 'ovt:0' shape=(1, 1) dtype=float32, numpy=array([[-0.04099093]], dtype=float32)>,\n",
       " <tf.Variable 'ivt:0' shape=(1, 4) dtype=float32, numpy=\n",
       " array([[ 0.05871323, -0.00726114, -0.00368669, -0.00105632]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'intercept:0' shape=(1, 3) dtype=float32, numpy=array([[-1.6874297, -0.3963601,  1.1344572]], dtype=float32)>]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmnl.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "keep_output": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.676656>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmnl.evaluate(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A faster specification can be done using a dictionnary. It follows torch-choice \\ref{} method to create conditional logit models.\n",
    "The parameters dict needs to be as follows:\n",
    "- The key is the feature name\n",
    "- The value is the mode. Currently three modes are available:\n",
    "    - constant: the learned coefficient is shared by all items\n",
    "    - item: one coefficient by item is estimated, the value for the item at index 0 is set to 0\n",
    "    - item-full: one coefficient by item is estimated\n",
    "\n",
    "In order to create the same model for the ModeCanada dataset, it looks as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiation of the parameters dictionnary\n",
    "params = {\"income\": \"item\",\n",
    " \"cost\": \"constant\", \n",
    " \"freq\": \"constant\",\n",
    " \"ovt\": \"constant\", \n",
    " \"ivt\": \"item-full\",\n",
    " \"intercept\": \"item\"}\n",
    "\n",
    "# Instantiation of the model\n",
    "cmnl = ConditionalMNL(parameters=params, optimizer=\"lbfgs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "keep_output": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature oh_air is in dataset but has no weight assigned in utility                            computations\n",
      "Feature oh_bus is in dataset but has no weight assigned in utility                            computations\n",
      "Feature oh_car is in dataset but has no weight assigned in utility                            computations\n",
      "Feature oh_train is in dataset but has no weight assigned in utility                            computations\n",
      "L-BFGS Opimization finished:\n",
      "---------------------------------------------------------------\n",
      "Number of iterations: 170\n",
      "Algorithm converged before reaching max iterations: True\n",
      "[<tf.Variable 'income:0' shape=(1, 3) dtype=float32, numpy=array([[-0.08908867, -0.02799244, -0.03814625]], dtype=float32)>, <tf.Variable 'cost:0' shape=(1, 1) dtype=float32, numpy=array([[-0.03333894]], dtype=float32)>, <tf.Variable 'freq:0' shape=(1, 1) dtype=float32, numpy=array([[0.09252954]], dtype=float32)>, <tf.Variable 'ovt:0' shape=(1, 1) dtype=float32, numpy=array([[-0.04300347]], dtype=float32)>, <tf.Variable 'ivt:0' shape=(1, 4) dtype=float32, numpy=\n",
      "array([[ 0.05950923, -0.00678411, -0.00646031, -0.00145046]],\n",
      "      dtype=float32)>, <tf.Variable 'intercept:0' shape=(1, 3) dtype=float32, numpy=array([[0.69846773, 1.8440608 , 3.2741735 ]], dtype=float32)>]\n"
     ]
    }
   ],
   "source": [
    "history = cmnl.fit(dataset, n_epochs=1000)\n",
    "print(cmnl.weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2: SwissMetro\n",
    "\n",
    "We reproduce the [PyLogit](https://github.com/timothyb0912/pylogit/blob/master/examples/notebooks/Main%20PyLogit%20Example.ipynb) example of ConditionalMNL, that is reproduction of a Biogeme example. It uses the SwissMetro dataset[3]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from choice_learn.datasets import load_swissmetro\n",
    "\n",
    "swiss_df = load_swissmetro(as_frame=True)\n",
    "\n",
    "# Removing unknown choices\n",
    "swiss_df = swiss_df.loc[swiss_df.CHOICE != 0]\n",
    "# Keep only commute an dbusiness trips\n",
    "swiss_df = swiss_df.loc[swiss_df.PURPOSE.isin([1, 3])]\n",
    "\n",
    "# Normalizing values\n",
    "swiss_df[[\"TRAIN_TT\", \"SM_TT\", \"CAR_TT\"]] = swiss_df[[\"TRAIN_TT\", \"SM_TT\", \"CAR_TT\"]] / 60.\n",
    "swiss_df[[\"TRAIN_HE\", \"SM_HE\"]] = swiss_df[[\"TRAIN_HE\", \"SM_HE\"]] / 60.\n",
    "\n",
    "swiss_df[\"train_free_ticket\"] = swiss_df.apply(lambda row: ((row[\"GA\"]==1 or row[\"WHO\"]==2) > 0).astype(int), axis=1)\n",
    "swiss_df[\"sm_free_ticket\"] = swiss_df.apply(lambda row: ((row[\"GA\"]==1 or row[\"WHO\"]==2) > 0).astype(int), axis=1)\n",
    "swiss_df[\"car_free_ticket\"] = 0\n",
    "\n",
    "swiss_df[\"train_travel_cost\"] = swiss_df.apply(lambda row: (row[\"TRAIN_CO\"] * (1 - row[\"train_free_ticket\"])) / 100, axis=1)\n",
    "swiss_df[\"sm_travel_cost\"] = swiss_df.apply(lambda row: (row[\"SM_CO\"] * (1 - row[\"sm_free_ticket\"])) / 100, axis=1)\n",
    "swiss_df[\"car_travel_cost\"] = swiss_df.apply(lambda row: row[\"CAR_CO\"] / 100, axis=1)\n",
    "\n",
    "swiss_df[\"single_luggage_piece\"] = swiss_df.apply(lambda row: (row[\"LUGGAGE\"] == 1).astype(int), axis=1)\n",
    "swiss_df[\"multiple_luggage_piece\"] = swiss_df.apply(lambda row: (row[\"LUGGAGE\"] == 3).astype(int), axis=1)\n",
    "swiss_df[\"regular_class\"] = swiss_df.apply(lambda row: 1 - row[\"FIRST\"], axis=1)\n",
    "swiss_df[\"train_survey\"] = swiss_df.apply(lambda row: 1 - row[\"SURVEY\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contexts_features = swiss_df[[\"train_survey\", \"FIRST\", \"single_luggage_piece\", \"multiple_luggage_piece\"]].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = swiss_df[[\"train_travel_cost\", \"TRAIN_TT\", \"TRAIN_HE\"]].to_numpy()\n",
    "sm_features = swiss_df[[\"SM_TT\", \"SM_CO\", \"SM_HE\", \"SM_SEATS\"]].to_numpy()\n",
    "car_features = swiss_df[[\"CAR_TT\", \"CAR_CO\"]].to_numpy()\n",
    "\n",
    "# We need to have the same number of features for each item, we create dummy ones:\n",
    "car_features = np.concatenate([car_features, np.zeros((len(car_features), 2))], axis=1)\n",
    "train_features = np.concatenate([train_features, np.zeros((len(train_features), 1))], axis=1)\n",
    "assert train_features.shape == car_features.shape == sm_features.shape\n",
    "\n",
    "contexts_items_features = np.stack([car_features, sm_features, train_features], axis=1)\n",
    "print(contexts_items_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contexts_items_availabilities = swiss_df[[\"CAR_AV\", \"SM_AV\", \"TRAIN_AV\"]].to_numpy()\n",
    "# Re-Indexing choices from 1 to 3 to 0 to 2\n",
    "choices = swiss_df.CHOICE.to_numpy() - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "swiss_dataset = ChoiceDataset(contexts_features=contexts_features,\n",
    "                                contexts_items_features=contexts_items_features,\n",
    "                                contexts_items_availabilities=contexts_items_availabilities,\n",
    "                                contexts_features_names=['GROUP', 'SURVEY', 'SP', 'ID', 'PURPOSE', 'FIRST', 'TICKET', 'WHO',\n",
    "                                                         'LUGGAGE', 'AGE', 'MALE', 'INCOME', 'GA', 'ORIGIN', 'DEST'],\n",
    "                                contexts_items_features_names=[\"TT\", \"CO\", \"HE\", \"SEATS\"],\n",
    "                                choices=choices\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "swiss_dataset.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization of the model\n",
    "swiss_model = ConditionalMNL(optimizer=\"lbfgs\")\n",
    "\n",
    "# Creation of the different weights:\n",
    "\n",
    "\n",
    "# add_coefficients adds one coefficient for each specified item_index\n",
    "# intercept, and income are added for each item except the first one that needs to be zeroed\n",
    "swiss_model.add_coefficients(coefficient_name=\"beta_inter\", feature_name=\"intercept\", items_indexes=[1, 2, 3])\n",
    "model.add_coefficients(coefficient_name=\"beta_income\", feature_name=\"income\", items_indexes=[1, 2, 3])\n",
    "\n",
    "# ivt is added for each item:\n",
    "model.add_coefficients(coefficient_name=\"beta_ivt\", feature_name=\"ivt\", items_indexes=[0, 1, 2, 3])\n",
    "\n",
    "# shared_coefficient add one coefficient that is used for all items specified in the items_indexes:\n",
    "# Here, cost, freq and ovt coefficients are shared between all items\n",
    "model.add_shared_coefficient(coefficient_name=\"beta_cost\", feature_name=\"cost\", items_indexes=[0, 1, 2, 3])\n",
    "model.add_shared_coefficient(coefficient_name=\"beta_freq\", feature_name=\"freq\", items_indexes=[0, 1, 2, 3])\n",
    "model.add_shared_coefficient(coefficient_name=\"beta_ovt\", feature_name=\"ovt\", items_indexes=[0, 1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
